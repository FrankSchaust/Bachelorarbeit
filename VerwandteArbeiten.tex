\section{Verwandte Arbeiten}
\label{VerwandteArbeiten}

In der Vergangenheit wurden diverse Arbeiten mit Bezug auf die Vorhersage von Kampfszenarien verfasst. \textcite{Kilmer.1996} diskutiert in seinem Artikel die Verwendung von ANNs zur Vorhersage von Gefechtsausgängen in Militärszenarien. Es werden mehrere Anwendungsfälle skizziert in denen ANNs Beiträge leisten können, wie u.a. das Ersetzen bestehender Simulationsverfahren durch ANN-basierte Modelle, oder aber auch das Optimieren bestehender Verfahren durch Erkenntnisse aus ANN-Simulationen.  

Da die Generierung reeller Daten aufwendig ist und solche Simluationen immer in Echtzeit ablaufen müssen, werden vermehrt Computersimulationen genutzt um Kampfszenarien zu erzeugen. Die Computerspiele StarCraft und StarCraft II waren schon mehrfach Anschauungsobjekt im Bezug auf Schlachtensimulation und der Vorhersage von Gefechtsausgängen. \textcite{AAAI:aimag/Robertson14} fasst Literatur zum Thema StarCraft zusammen und arbeitet Forschungsfelder oder Aufgaben heraus, welche einen positiven Einfluss auf die Forschung im Bereich der künstlichen Intelligenz (KI) haben könnten. Robertson kommt zu dem Schluss, dass Machine Learning bei der Verbesserung bestehender KIs an Einfluss gewinnen wird und dass ein klarer Trend zu Machine Learning-Verfahren zu erkennen ist. 
\textcite{AIIDE137381, AIIDE125469, AIIDE1511531, SnchezRuizGranados2015PredictingTO, 6633643, 6374183} nutzen für ihre Beiträge die Spielumgebung von StarCraft, während \textcite{DBLP:journals/corr/HelmkeKW14, samvelyan2019starcraft} ihre Methoden in der Umgebung von StarCraft II entwickeln und testen. Die Arbeiten von  \textcite{6633643, AIIDE125469, DBLP:journals/corr/HelmkeKW14} beschäftigen sich mit der Vorhersage von Gefechtsausgängen unter Verwendung von Simulationsverfahren. \textcite{SnchezRuizGranados2015PredictingTO, AIIDE137381, AIIDE1511531} nutzen unterschiedliche Machine Learning Verfahren um Gefechte vorherzusagen. 

\textcite{AIIDE137381} stellt ein Modell vor, auf dessen Basis ein Lernalgorithmus die offensiven und defensiven Feature Values (zu Deutsch: \textit{Eigenschaftswerte}) jeder Einheit erlernt. Das Modell basiert auf offensiven und defensiven Merkmalen jeder Einheit, welche zu offensiven und defensiven Eigenschaften einer Armee verrechnet werden. Da sich die Arbeit auf die Zusammensetzung von Armeen beschränkt, vernachlässigt es einige Faktoren, welche bei einer ganzheitlichen Betrachtung von Gefechten eine Rolle spielen. So wird Terrain und die Vor- und Nachteile die es mit sich bringt, außer Acht gelassen, fliegende Einheiten, sowie Einheiten, die Fähigkeiten nutzen werden ignoriert und Einheitenverbesserungen sind in dem Modell auch nicht existent. 

\textcite{AIIDE125469} entwickelt einen Such-Algorithmus, der basierend auf einen Spiel-Zustand optimale Entscheidungen für eine KI treffen soll. Da die Suche nach einer optimalen Entscheidung oftmals langwierig sein kann, wird die maximale Dauer der Evaluierung in der aktiven Anwendung in einer KI auf 5ms beschränkt. Trotz dieser Einschränkung schafft es der Algorithmus einfache KI-Skripte zu schlagen. Das Modell des Algorithmus modelliert den Zustand des Spiels und jeder einzelnen Einheit und errechnet für jeden Zeitschritt eine Menge an Legal Moves (zu Deutsch: \textit{legale/erlaubte Züge}). Das Modell unterliegt einigen Limitierungen, die seine Nutzbarkeit einschränken. So werden Trefferpunktregeneration, Einheitenkollision und Reisezeit von Projektilen nicht in die Evaluierung einbezogen. 

Stanescu et al. \textcite{AIIDE1511531} bauen ihren Vorhersage-Algorithmus auf dem Gesetz von Lanchester (auch Lanchester's Square Law genannt) auf, welches er in seinem Buch \textit{ Aircraft in Warfare – The Dawn of the Fourth Arm} von 1916 formuliert. Hierbei handelt es sich um ein Modell, welches versucht die Verluste in militärischen Gefechtssituationen  einzuschätzen. Basierend auf Lanchester wird ein Algorithmus vorgestellt, welcher durch vergangene Gefechte seine Parameter anpassen kann. Der Algorithmus ersetzt unter Turnierbedingungen den simulationsbasierten Entscheidungsalgorithmus des UAlbertaBots im Bezug auf die Entscheidung ein Gefecht einzugehen oder sich zurückzuziehen. Das Modell zieht Interaktionen zwischen Einheiten, wie z.B. das Heilen durch Medics nicht in Betracht und ignoriert Einheitenpositionierung.  

\textcite{SnchezRuizGranados2015PredictingTO} beschränkt sich auf die Vorhersage der Gefecht und vergleicht die Präzision der verschiedenen Machine Learning Algorithmen. Es werden im Allgemeinen vier Feature (zu Deutsch: \textit{Merkmale}) zur Evaluierung definiert: Die Anzahl der Einheiten, ihr durchschnittliches Leben und ihre relative Position, sowie Distanz zur gegnerischen Armee. Die relative Position wird angenähert, indem um jede Armee ein minimales Rechteck gezogen wird, dessen Fläche bildet steht stellvertretend für die Streuung der Einheiten. Die Distanz zur feindlichen Armee wird bestimmt durch die Entfernung der Mittelpunkte beider Rechtecke. Die Vordefinierten Features beziehen sich nicht auf Merkmale der einzelnen Einheiten, sondern stellen die Armeen in den Fokus. Es werden daher einheitenspezifische Merkmale wie Schadenswerte der Einheiten, Rüstung oder Reichweite ignoriert.

Portfolio greedy search \parencite{6633643} ist ein Such-Algorithmus, der -- ähnlich wie \textcite{AIIDE125469} -- versucht Handlungsfolgen zu konstruieren, welche auf Gefechts-Szenarien mit bis zu 50 Einheiten pro Seite angewandt werden können. Im Zuge der Entwicklung konnten Churchill und Buro ebenfalls SparCraft vorstellen. Ein System mit dem Gefechte abstrakt modelliert werden können. 

Wender und Watson haben vorgestellt, wie Reinforcment Learning (zu Deutsch: \textit{Bestärkendes Lernen}) in StarCraft Anwendung finden kann \parencite{6374183}. Der von ihnen vorgestellte Algorithmus sollte das Mikromanagement der Einheiten erlernen und schlussendlich geskriptete Abfolgen ablösen. In ihrem Paper zeigten sie, dass Reinforcement Learning ein geeignetes Verfahren für diese Domäne ist. 

\textcite{DBLP:journals/corr/HelmkeKW14} entwickelt Näherungsmodelle basierend auf eingespeisten Grundkonstellationen für das Spiel StarCraft II. In dem Paper werden 4 Annäherungsmethoden vorgestellt, welche unterschiedliche Eigenschaften der beiden Armeen in Betracht ziehen. Es werden jedoch Einheiten-Fähigkeiten, sowie Einheitenverbesserungen vernachlässigt. Außerdem werden Einheitentypen, wie nicht modelliert. Da einige Einheiten nur Einheiten eines speziellen Typs angreifen können führt das zu Unschärfen in der Vorhersage. Des weiteren wird die Position der Einheiten nicht mit einbezogen. 

\textcite{samvelyan2019starcraft} befasst sich mit den Problemen von Multi-Agent Reinforcement Learning (MARL). In dem Paper werden sogenannte Benchmark-Probleme für MARL eingeführt. Außerdem veröffentlichen die Verfasser mit \textit{PyMARL} ihr Framework (zu Deutsch etwa: \textit{Gerüst}) für die Erstellung und Analyse von tiefen MARL-Algorithmen. 